# ========================================
# Bisheng Enterprise - Prometheus Alert Rules
# ========================================
# Alert definitions for monitoring
# ========================================

groups:

  # ==================== System Alerts ====================
  - name: system_alerts
    interval: 30s
    rules:
      
      # High CPU Usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          category: system
        annotations:
          summary: "High CPU usage detected on {{ $labels.instance }}"
          description: "CPU usage is above 80% (current: {{ $value | humanize }}%)"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
          category: system
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% (current: {{ $value | humanize }}%)"

      # Disk Space Low
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 15
        for: 5m
        labels:
          severity: warning
          category: system
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk space is below 15% ({{ $labels.mountpoint }})"

      # Disk Space Critical
      - alert: DiskSpaceCritical
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 10
        for: 2m
        labels:
          severity: critical
          category: system
        annotations:
          summary: "Critical disk space on {{ $labels.instance }}"
          description: "Disk space is below 10% ({{ $labels.mountpoint }})"

  # ==================== Service Alerts ====================
  - name: service_alerts
    interval: 30s
    rules:

      # Service Down
      - alert: ServiceDown
        expr: up == 0
        for: 2m
        labels:
          severity: critical
          category: service
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.instance }} has been down for more than 2 minutes"

      # Service Flapping
      - alert: ServiceFlapping
        expr: changes(up[10m]) > 5
        for: 5m
        labels:
          severity: warning
          category: service
        annotations:
          summary: "Service {{ $labels.job }} is flapping"
          description: "{{ $labels.instance }} has restarted {{ $value }} times in the last 10 minutes"

  # ==================== PostgreSQL Alerts ====================
  - name: postgresql_alerts
    interval: 30s
    rules:

      # PostgreSQL Down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          category: database
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance {{ $labels.instance }} is down"

      # High Connection Usage
      - alert: PostgreSQLHighConnections
        expr: (pg_stat_database_numbackends / pg_settings_max_connections) * 100 > 80
        for: 5m
        labels:
          severity: warning
          category: database
        annotations:
          summary: "PostgreSQL high connection usage"
          description: "Connection usage is above 80% (current: {{ $value | humanize }}%)"

      # Slow Queries
      - alert: PostgreSQLSlowQueries
        expr: rate(pg_stat_activity_max_tx_duration[5m]) > 60
        for: 5m
        labels:
          severity: warning
          category: database
        annotations:
          summary: "PostgreSQL slow queries detected"
          description: "Long-running queries detected on {{ $labels.instance }}"

      # Replication Lag
      - alert: PostgreSQLReplicationLag
        expr: pg_replication_lag > 30
        for: 5m
        labels:
          severity: warning
          category: database
        annotations:
          summary: "PostgreSQL replication lag"
          description: "Replication lag is {{ $value }} seconds"

  # ==================== Redis Alerts ====================
  - name: redis_alerts
    interval: 30s
    rules:

      # Redis Down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          category: cache
        annotations:
          summary: "Redis is down"
          description: "Redis instance {{ $labels.instance }} is down"

      # High Memory Usage
      - alert: RedisHighMemory
        expr: (redis_memory_used_bytes / redis_memory_max_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
          category: cache
        annotations:
          summary: "Redis high memory usage"
          description: "Memory usage is above 90% (current: {{ $value | humanize }}%)"

      # Too Many Connections
      - alert: RedisTooManyConnections
        expr: redis_connected_clients > 1000
        for: 5m
        labels:
          severity: warning
          category: cache
        annotations:
          summary: "Redis too many connections"
          description: "Redis has {{ $value }} connections"

  # ==================== Elasticsearch Alerts ====================
  - name: elasticsearch_alerts
    interval: 30s
    rules:

      # Elasticsearch Down
      - alert: ElasticsearchDown
        expr: elasticsearch_cluster_health_up == 0
        for: 1m
        labels:
          severity: critical
          category: search
        annotations:
          summary: "Elasticsearch is down"
          description: "Elasticsearch cluster is down"

      # Cluster Health Red
      - alert: ElasticsearchClusterRed
        expr: elasticsearch_cluster_health_status{color="red"} == 1
        for: 5m
        labels:
          severity: critical
          category: search
        annotations:
          summary: "Elasticsearch cluster health is RED"
          description: "Elasticsearch cluster health is in RED state"

      # Cluster Health Yellow
      - alert: ElasticsearchClusterYellow
        expr: elasticsearch_cluster_health_status{color="yellow"} == 1
        for: 10m
        labels:
          severity: warning
          category: search
        annotations:
          summary: "Elasticsearch cluster health is YELLOW"
          description: "Elasticsearch cluster health is in YELLOW state"

  # ==================== Milvus Alerts ====================
  - name: milvus_alerts
    interval: 30s
    rules:

      # Milvus Down
      - alert: MilvusDown
        expr: up{job="milvus"} == 0
        for: 2m
        labels:
          severity: critical
          category: vectordb
        annotations:
          summary: "Milvus is down"
          description: "Milvus instance is down"

  # ==================== Application Alerts ====================
  - name: application_alerts
    interval: 30s
    rules:

      # High Response Time
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          category: application
        annotations:
          summary: "High response time on {{ $labels.job }}"
          description: "95th percentile response time is {{ $value | humanize }}s"

      # High Error Rate
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          category: application
        annotations:
          summary: "High error rate on {{ $labels.job }}"
          description: "Error rate is {{ $value | humanizePercentage }}"

      # No Requests
      - alert: NoRequests
        expr: rate(http_requests_total[10m]) == 0
        for: 10m
        labels:
          severity: warning
          category: application
        annotations:
          summary: "No requests received"
          description: "{{ $labels.job }} has not received any requests in 10 minutes"

  # ==================== Container Alerts ====================
  - name: container_alerts
    interval: 30s
    rules:

      # Container High CPU
      - alert: ContainerHighCPU
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
          category: container
        annotations:
          summary: "Container {{ $labels.name }} high CPU"
          description: "CPU usage is {{ $value | humanize }}%"

      # Container High Memory
      - alert: ContainerHighMemory
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
          category: container
        annotations:
          summary: "Container {{ $labels.name }} high memory"
          description: "Memory usage is {{ $value | humanize }}%"

      # Container Restart
      - alert: ContainerRestart
        expr: rate(container_last_seen[5m]) > 0
        for: 1m
        labels:
          severity: warning
          category: container
        annotations:
          summary: "Container {{ $labels.name }} restarted"
          description: "Container has been restarted"

# EOF
